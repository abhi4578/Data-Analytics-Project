{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_2011=\"./Data Base/used data sets/google flu trend data/gtf_2011\"\n",
    "gtf_2011= pd.read_table(gtf_2011,sep=',')\n",
    "gtf_2011=np.array(gtf_2011[gtf_2011.keys()[1:]])\n",
    "\n",
    "gtf_2012=\"./Data Base/used data sets/google flu trend data/gtf_2012\"\n",
    "gtf_2012= pd.read_table(gtf_2012,sep=',')\n",
    "gtf_2012=np.array(gtf_2012[gtf_2012.keys()[1:]])\n",
    "\n",
    "gtf_2013=\"./Data Base/used data sets/google flu trend data/gtf_2013\"\n",
    "gtf_2013= pd.read_table(gtf_2013,sep=',')\n",
    "gtf_2013=np.array(gtf_2013[gtf_2013.keys()[1:]])\n",
    "\n",
    "gtf_2014=\"./Data Base/used data sets/google flu trend data/gtf_2014\"\n",
    "gtf_2014= pd.read_table(gtf_2014,sep=',')\n",
    "gtf_2014=np.array(gtf_2014[gtf_2014.keys()[1:]])\n",
    "\n",
    "\n",
    "CDC_2011=\"./Data Base/used data sets/google flu trend data/ILINet_2011.csv\"\n",
    "CDC_2011= pd.read_csv(CDC_2011)\n",
    "CDC_2011=np.array(CDC_2011[['TOTAL PATIENTS']])\n",
    "\n",
    "CDC_2012=\"./Data Base/used data sets/google flu trend data/ILINet_2012.csv\"\n",
    "CDC_2012= pd.read_csv(CDC_2012)\n",
    "CDC_2012=np.array(CDC_2012[['TOTAL PATIENTS']])\n",
    "\n",
    "CDC_2013=\"./Data Base/used data sets/google flu trend data/ILINet_2013.csv\"\n",
    "CDC_2013= pd.read_csv(CDC_2013)\n",
    "CDC_2013=np.array(CDC_2013[['TOTAL PATIENTS']])\n",
    "\n",
    "CDC_2014=\"./Data Base/used data sets/google flu trend data/ILINet_2014.csv\"\n",
    "CDC_2014= pd.read_csv(CDC_2014)\n",
    "CDC_2014=np.array(CDC_2014[['TOTAL PATIENTS']])\n",
    "\n",
    "gtf_2011=np.append(gtf_2011,CDC_2011,axis=1)\n",
    "gtf_2012=np.append(gtf_2012,CDC_2012,axis=1)\n",
    "gtf_2013=np.append(gtf_2013,CDC_2013,axis=1)\n",
    "gtf_2014=np.append(gtf_2014,CDC_2014,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_0_lag=[]\n",
    "x_test_0_lag=[]\n",
    "x_train_1_lag=[]\n",
    "x_test_1_lag=[]\n",
    "x_train_2_lag=[]\n",
    "x_test_2_lag=[]\n",
    "x_train_3_lag=[]\n",
    "x_test_3_lag=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero lag \n",
    "for i in [gtf_2011,gtf_2012]:\n",
    "    for j in range(i.shape[0]-3):\n",
    "        x_train_0_lag.append(np.append(np.array([i[j][-1],i[j+1][-1],i[j+2][-1]]),i[j+3][:-1]))\n",
    "x_train_0_lag=np.array(x_train_0_lag)\n",
    "for i in [gtf_2013,gtf_2014]:\n",
    "    for j in range(i.shape[0]-3):\n",
    "        x_test_0_lag.append(np.append(np.array([i[j][-1],i[j+1][-1],i[j+2][-1]]),i[j+3][:-1]))\n",
    "x_test_0_lag=np.array(x_test_0_lag)\n",
    "\n",
    "# one lag \n",
    "for i in [gtf_2011,gtf_2012]:\n",
    "    for j in range(i.shape[0]-4):\n",
    "        x_train_1_lag.append(np.append(np.array([i[j][-1],i[j+1][-1],i[j+2][-1]]),i[j+3][:-1]))\n",
    "x_train_1_lag=np.array(x_train_1_lag)\n",
    "for i in [gtf_2013,gtf_2014]:\n",
    "    for j in range(i.shape[0]-4):\n",
    "        x_test_1_lag.append(np.append(np.array([i[j][-1],i[j+1][-1],i[j+2][-1]]),i[j+3][:-1]))\n",
    "x_test_1_lag=np.array(x_test_1_lag)\n",
    "\n",
    "# two lag \n",
    "for i in [gtf_2011,gtf_2012]:\n",
    "    for j in range(i.shape[0]-5):\n",
    "        x_train_2_lag.append(np.append(np.array([i[j][-1],i[j+1][-1],i[j+2][-1]]),i[j+3][:-1]))\n",
    "x_train_2_lag=np.array(x_train_2_lag)\n",
    "for i in [gtf_2013,gtf_2014]:\n",
    "    for j in range(i.shape[0]-5):\n",
    "        x_test_2_lag.append(np.append(np.array([i[j][-1],i[j+1][-1],i[j+2][-1]]),i[j+3][:-1]))\n",
    "x_test_2_lag=np.array(x_test_2_lag)\n",
    "\n",
    "# three lag \n",
    "for i in [gtf_2011,gtf_2012]:\n",
    "    for j in range(i.shape[0]-6):\n",
    "        x_train_3_lag.append(np.append(np.array([i[j][-1],i[j+1][-1],i[j+2][-1]]),i[j+3][:-1]))\n",
    "x_train_3_lag=np.array(x_train_3_lag)\n",
    "for i in [gtf_2013,gtf_2014]:\n",
    "    for j in range(i.shape[0]-6):\n",
    "        x_test_3_lag.append(np.append(np.array([i[j][-1],i[j+1][-1],i[j+2][-1]]),i[j+3][:-1]))\n",
    "x_test_3_lag=np.array(x_test_3_lag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label preperation\n",
    "# zero lag \n",
    "y_train_0_lag=np.concatenate((gtf_2011[:,-1][3:],gtf_2012[:,-1][3:]))\n",
    "y_test_0_lag=np.concatenate((gtf_2013[:,-1][3:],gtf_2014[:,-1][3:]))\n",
    "# one lag \n",
    "y_train_1_lag=np.concatenate((gtf_2011[:,-1][4:],gtf_2012[:,-1][4:]))\n",
    "y_test_1_lag=np.concatenate((gtf_2013[:,-1][4:],gtf_2014[:,-1][4:]))\n",
    "# two lag \n",
    "y_train_2_lag=np.concatenate((gtf_2011[:,-1][5:],gtf_2012[:,-1][5:]))\n",
    "y_test_2_lag=np.concatenate((gtf_2013[:,-1][5:],gtf_2014[:,-1][5:]))\n",
    "# three lag \n",
    "y_train_3_lag=np.concatenate((gtf_2011[:,-1][6:],gtf_2012[:,-1][6:]))\n",
    "y_test_3_lag=np.concatenate((gtf_2013[:,-1][6:],gtf_2014[:,-1][6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(len(x_train_0_lag)):\n",
    "    transformed, lmbda = boxcox(x_train_0_lag[i])\n",
    "    data.append(transformed)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-34.444650069847846"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero lag\n",
    "reg0 = LinearSVR().fit(data,y_train_0_lag )\n",
    "reg0.score(data,y_train_0_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12997966.994421475"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg0.score(x_test_0_lag,y_test_0_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the coefficient of determination R^2 of the prediction.\n",
    "# The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() \n",
    "# and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can \n",
    "# be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value \n",
    "# of y, disregarding the input features, would get a R^2 score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg.predict(x_test_0_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.663848376436833"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one lag\n",
    "reg1 = LinearSVR().fit(x_train_1_lag,y_train_1_lag )\n",
    "reg1.score(x_train_1_lag,y_train_1_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6661724506389188"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1.score(x_test_1_lag,y_test_1_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5203553693592734"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two lag\n",
    "reg2 = LinearSVR().fit(x_train_2_lag,y_train_2_lag )\n",
    "reg2.score(x_train_2_lag,y_train_2_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4937260326928104"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.score(x_test_2_lag,y_test_2_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48140954961253424"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three lag\n",
    "reg3 =LinearSVR().fit(x_train_3_lag,y_train_3_lag )\n",
    "reg3.score(x_train_3_lag,y_train_3_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39681728370601055"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg3.score(x_test_3_lag,y_test_3_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_0_p_train=reg0.predict(x_train_0_lag)\n",
    "gtf_0_a_train=y_train_0_lag\n",
    "gtf_0_p_test=reg0.predict(x_test_0_lag)\n",
    "gtf_0_a_test=y_test_0_lag\n",
    "\n",
    "gtf_1_p_train=reg1.predict(x_train_1_lag)\n",
    "gtf_1_a_train=y_train_1_lag\n",
    "gtf_1_p_test=reg1.predict(x_test_1_lag)\n",
    "gtf_1_a_test=y_test_1_lag\n",
    "\n",
    "gtf_2_p_train=reg2.predict(x_train_2_lag)\n",
    "gtf_2_a_train=y_train_2_lag\n",
    "gtf_2_p_test=reg2.predict(x_test_2_lag)\n",
    "gtf_2_a_test=y_test_2_lag\n",
    "\n",
    "gtf_3_p_train=reg3.predict(x_train_3_lag)\n",
    "gtf_3_a_train=y_train_3_lag\n",
    "gtf_3_p_test=reg3.predict(x_test_3_lag)\n",
    "gtf_3_a_test=y_test_3_lag\n",
    "\n",
    "np.save(\"gtf_0_p_test\",gtf_0_p_test)\n",
    "np.save(\"gtf_0_a_test\",gtf_0_a_test)\n",
    "np.save(\"gtf_0_p_train\",gtf_0_p_train)\n",
    "np.save(\"gtf_0_a_train\",gtf_0_a_train)\n",
    "np.save(\"gtf_1_p_test\",gtf_1_p_test)\n",
    "np.save(\"gtf_1_a_test\",gtf_1_a_test)\n",
    "np.save(\"gtf_1_p_train\",gtf_1_p_train)\n",
    "np.save(\"gtf_1_a_train\",gtf_1_a_train)\n",
    "np.save(\"gtf_2_p_test\",gtf_2_p_test)\n",
    "np.save(\"gtf_2_a_test\",gtf_2_a_test)\n",
    "np.save(\"gtf_2_p_train\",gtf_2_p_train)\n",
    "np.save(\"gtf_2_a_train\",gtf_2_a_train)\n",
    "np.save(\"gtf_3_p_test\",gtf_3_p_test)\n",
    "np.save(\"gtf_3_a_test\",gtf_3_a_test)\n",
    "np.save(\"gtf_3_p_train\",gtf_3_p_train)\n",
    "np.save(\"gtf_3_a_train\",gtf_3_a_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
