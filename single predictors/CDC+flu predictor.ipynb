{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_2011=\"./Data Base/used data sets/flutwitter data/fluTwitterData_2011.csv\"\n",
    "flu_2011= pd.read_csv(flu_2011)\n",
    "flu_2011=np.array(flu_2011[['nILI', 'nRTs', 'nTweets','nPatients']])\n",
    "\n",
    "flu_2012=\"./Data Base/used data sets/flutwitter data/fluTwitterData_2012.csv\"\n",
    "flu_2012= pd.read_csv(flu_2012)\n",
    "flu_2012=np.array(flu_2012[['nILI', 'nRTs', 'nTweets','nPatients']])\n",
    "\n",
    "flu_2013=\"./Data Base/used data sets/flutwitter data/fluTwitterData_2013.csv\"\n",
    "flu_2013= pd.read_csv(flu_2013)\n",
    "flu_2013=np.array(flu_2013[[ 'nILI', 'nRTs', 'nTweets','nPatients']])\n",
    "\n",
    "flu_2014=\"./Data Base/used data sets/flutwitter data/fluTwitterData_2014.csv\"\n",
    "flu_2014= pd.read_csv(flu_2014)\n",
    "flu_2014=np.array(flu_2014[[ 'nILI', 'nRTs', 'nTweets','nPatients']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_0_lag=[]\n",
    "x_test_0_lag=[]\n",
    "x_train_1_lag=[]\n",
    "x_test_1_lag=[]\n",
    "x_train_2_lag=[]\n",
    "x_test_2_lag=[]\n",
    "x_train_3_lag=[]\n",
    "x_test_3_lag=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero lag \n",
    "for i in [flu_2011,flu_2012]:\n",
    "    for j in range(i.shape[0]-3):\n",
    "        x_train_0_lag.append([i[j][-1],i[j+1][-1],i[j+2][-1],i[j+3][0],i[j+3][1],i[j+3][2]])\n",
    "x_train_0_lag=np.array(x_train_0_lag)\n",
    "for i in [flu_2013,flu_2014]:\n",
    "    for j in range(i.shape[0]-3):\n",
    "        x_test_0_lag.append([i[j][-1],i[j+1][-1],i[j+2][-1],i[j+3][0],i[j+3][1],i[j+3][2]])\n",
    "x_test_0_lag=np.array(x_test_0_lag)\n",
    "\n",
    "# one lag \n",
    "for i in [flu_2011,flu_2012]:\n",
    "    for j in range(i.shape[0]-4):\n",
    "        x_train_1_lag.append([i[j][-1],i[j+1][-1],i[j+2][-1],i[j+3][0],i[j+3][1],i[j+3][2]])\n",
    "x_train_1_lag=np.array(x_train_1_lag)\n",
    "for i in [flu_2013,flu_2014]:\n",
    "    for j in range(i.shape[0]-4):\n",
    "        x_test_1_lag.append([i[j][-1],i[j+1][-1],i[j+2][-1],i[j+3][0],i[j+3][1],i[j+3][2]])\n",
    "x_test_1_lag=np.array(x_test_1_lag)\n",
    "\n",
    "# two lag \n",
    "for i in [flu_2011,flu_2012]:\n",
    "    for j in range(i.shape[0]-5):\n",
    "        x_train_2_lag.append([i[j][-1],i[j+1][-1],i[j+2][-1],i[j+3][0],i[j+3][1],i[j+3][2]])\n",
    "x_train_2_lag=np.array(x_train_2_lag)\n",
    "for i in [flu_2013,flu_2014]:\n",
    "    for j in range(i.shape[0]-5):\n",
    "        x_test_2_lag.append([i[j][-1],i[j+1][-1],i[j+2][-1],i[j+3][0],i[j+3][1],i[j+3][2]])\n",
    "x_test_2_lag=np.array(x_test_2_lag)\n",
    "\n",
    "# three lag \n",
    "for i in [flu_2011,flu_2012]:\n",
    "    for j in range(i.shape[0]-6):\n",
    "        x_train_3_lag.append([i[j][-1],i[j+1][-1],i[j+2][-1],i[j+3][0],i[j+3][1],i[j+3][2]])\n",
    "x_train_3_lag=np.array(x_train_3_lag)\n",
    "for i in [flu_2013,flu_2014]:\n",
    "    for j in range(i.shape[0]-6):\n",
    "        x_test_3_lag.append([i[j][-1],i[j+1][-1],i[j+2][-1],i[j+3][0],i[j+3][1],i[j+3][2]])\n",
    "x_test_3_lag=np.array(x_test_3_lag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label preperation\n",
    "# zero lag \n",
    "y_train_0_lag=np.concatenate((flu_2011[:,-1][3:],flu_2012[:,-1][3:]))\n",
    "y_test_0_lag=np.concatenate((flu_2013[:,-1][3:],flu_2014[:,-1][3:]))\n",
    "# one lag \n",
    "y_train_1_lag=np.concatenate((flu_2011[:,-1][4:],flu_2012[:,-1][4:]))\n",
    "y_test_1_lag=np.concatenate((flu_2013[:,-1][4:],flu_2014[:,-1][4:]))\n",
    "# two lag \n",
    "y_train_2_lag=np.concatenate((flu_2011[:,-1][5:],flu_2012[:,-1][5:]))\n",
    "y_test_2_lag=np.concatenate((flu_2013[:,-1][5:],flu_2014[:,-1][5:]))\n",
    "# three lag \n",
    "y_train_3_lag=np.concatenate((flu_2011[:,-1][6:],flu_2012[:,-1][6:]))\n",
    "y_test_3_lag=np.concatenate((flu_2013[:,-1][6:],flu_2014[:,-1][6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642172070732113"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero lag\n",
    "reg0 = LinearRegression().fit(x_train_0_lag,y_train_0_lag )\n",
    "reg0.score(x_train_0_lag,y_train_0_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7023392587406077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg0.score(x_test_0_lag,y_test_0_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the coefficient of determination R^2 of the prediction.\n",
    "# The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() \n",
    "# and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can \n",
    "# be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value \n",
    "# of y, disregarding the input features, would get a R^2 score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg.predict(x_test_0_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6503338986954308"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one lag\n",
    "reg1 = LinearRegression().fit(x_train_1_lag,y_train_1_lag )\n",
    "reg1.score(x_train_1_lag,y_train_1_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6344233314195895"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1.score(x_test_1_lag,y_test_1_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.542878138047139"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two lag\n",
    "reg2 = LinearRegression().fit(x_train_2_lag,y_train_2_lag )\n",
    "reg2.score(x_train_2_lag,y_train_2_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5420188309697129"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.score(x_test_2_lag,y_test_2_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5112047895565073"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three lag\n",
    "reg3 = LinearRegression().fit(x_train_3_lag,y_train_3_lag )\n",
    "reg3.score(x_train_3_lag,y_train_3_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5113629679148739"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg3.score(x_test_3_lag,y_test_3_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_flu_0_p_train=reg0.predict(x_train_0_lag)\n",
    "cdc_flu_0_a_train=y_train_0_lag\n",
    "cdc_flu_0_p_test=reg0.predict(x_test_0_lag)\n",
    "cdc_flu_0_a_test=y_test_0_lag\n",
    "\n",
    "cdc_flu_1_p_train=reg1.predict(x_train_1_lag)\n",
    "cdc_flu_1_a_train=y_train_1_lag\n",
    "cdc_flu_1_p_test=reg1.predict(x_test_1_lag)\n",
    "cdc_flu_1_a_test=y_test_1_lag\n",
    "\n",
    "cdc_flu_2_p_train=reg2.predict(x_train_2_lag)\n",
    "cdc_flu_2_a_train=y_train_2_lag\n",
    "cdc_flu_2_p_test=reg2.predict(x_test_2_lag)\n",
    "cdc_flu_2_a_test=y_test_2_lag\n",
    "\n",
    "cdc_flu_3_p_train=reg3.predict(x_train_3_lag)\n",
    "cdc_flu_3_a_train=y_train_3_lag\n",
    "cdc_flu_3_p_test=reg3.predict(x_test_3_lag)\n",
    "cdc_flu_3_a_test=y_test_3_lag\n",
    "\n",
    "np.save(\"cdc_flu_0_p_test\",cdc_flu_0_p_test)\n",
    "np.save(\"cdc_flu_0_a_test\",cdc_flu_0_a_test)\n",
    "np.save(\"cdc_flu_0_p_train\",cdc_flu_0_p_train)\n",
    "np.save(\"cdc_flu_0_a_train\",cdc_flu_0_a_train)\n",
    "np.save(\"cdc_flu_1_p_test\",cdc_flu_1_p_test)\n",
    "np.save(\"cdc_flu_1_a_test\",cdc_flu_1_a_test)\n",
    "np.save(\"cdc_flu_1_p_train\",cdc_flu_1_p_train)\n",
    "np.save(\"cdc_flu_1_a_train\",cdc_flu_1_a_train)\n",
    "np.save(\"cdc_flu_2_p_test\",cdc_flu_2_p_test)\n",
    "np.save(\"cdc_flu_2_a_test\",cdc_flu_2_a_test)\n",
    "np.save(\"cdc_flu_2_p_train\",cdc_flu_2_p_train)\n",
    "np.save(\"cdc_flu_2_a_train\",cdc_flu_2_a_train)\n",
    "np.save(\"cdc_flu_3_p_test\",cdc_flu_3_p_test)\n",
    "np.save(\"cdc_flu_3_a_test\",cdc_flu_3_a_test)\n",
    "np.save(\"cdc_flu_3_p_train\",cdc_flu_3_p_train)\n",
    "np.save(\"cdc_flu_3_a_train\",cdc_flu_3_a_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
